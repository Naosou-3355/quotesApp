#!/usr/bin/env python3
"""
convert_to_json.py
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Convertit votre fichier Excel, CSV ou TSV (Google Sheets) en data.json
utilisable par l'application QuoteApp.

Probl√®mes r√©solus :
  ‚úì Accents et caract√®res fran√ßais (UTF-8 avec BOM g√©r√© automatiquement)
  ‚úì Virgules dans les phrases (guillemets RFC 4180 ou format TSV)
  ‚úì S√©parateur auto-d√©tect√© (virgule, point-virgule, tabulation)

Usage :
  python convert_to_json.py                     ‚Üí cherche auto le fichier
  python convert_to_json.py mon_fichier.csv     ‚Üí CSV sp√©cifique
  python convert_to_json.py mon_fichier.tsv     ‚Üí TSV (recommand√©)
  python convert_to_json.py mon_fichier.xlsx    ‚Üí Excel

D√©pendances :
  pip install pandas openpyxl
"""

import sys
import json
import os
import csv
import glob
from pathlib import Path

try:
    import pandas as pd
except ImportError:
    print("‚ùå  pandas manquant. Installez-le : pip install pandas openpyxl")
    sys.exit(1)


def find_file():
    """Cherche automatiquement un fichier dans le dossier courant, TSV en priorit√©."""
    for pattern in ["*.tsv", "*.csv", "*.xlsx", "*.xls"]:
        files = glob.glob(pattern)
        if files:
            return files[0]
    return None


def open_with_encoding(filepath):
    """
    Ouvre le fichier texte en g√©rant le BOM UTF-8 (0xEF 0xBB 0xBF).
    Ce BOM est ajout√© silencieusement par Google Sheets et Excel Windows.
    Sans gestion, il cr√©e le caract√®re parasite '√Ø¬ª¬ø' en t√™te du fichier,
    ce qui emp√™che de reconna√Ætre le nom de la premi√®re colonne (Horodateur, etc.).
    'utf-8-sig' est l'encodage Python qui strips automatiquement ce BOM.
    """
    encodings = ["utf-8-sig", "utf-8", "latin-1", "cp1252"]
    for enc in encodings:
        try:
            with open(filepath, "r", encoding=enc, newline="") as f:
                lines = f.readlines()
            print(f"    Encodage d√©tect√© : {enc}")
            return lines
        except (UnicodeDecodeError, LookupError):
            continue
    raise ValueError("Impossible de lire le fichier ‚Äî encodage non reconnu.")


def load_file(filepath):
    ext = Path(filepath).suffix.lower()
    print(f"üìÇ  Format : {ext.upper()}")

    if ext in (".xlsx", ".xls"):
        df = pd.read_excel(filepath, dtype=str).fillna("")
        return df

    raw = open_with_encoding(filepath)

    if ext == ".tsv":
        sep = "\t"
        print("    S√©parateur : tabulation (TSV ‚Äî virgules dans les phrases OK)")
    else:
        sample = "".join(raw[:10])
        counts = {",": sample.count(","), ";": sample.count(";"), "\t": sample.count("\t")}
        sep = max(counts, key=counts.get)
        labels = {",": "virgule", ";": "point-virgule", "\t": "tabulation"}
        print(f"    S√©parateur d√©tect√© : {labels[sep]}")

    from io import StringIO
    text = "".join(raw)

    df = pd.read_csv(
        StringIO(text),
        sep=sep,
        dtype=str,
        quotechar='"',          # champs avec virgules encadr√©s par guillemets doubles (RFC 4180)
        doublequote=True,       # "" dans un champ = guillemet litt√©ral
        engine="python",        # parser plus robuste pour les cas limites
        on_bad_lines="warn",
    ).fillna("").apply(lambda col: col.str.strip() if col.dtype == object else col)

    return df


def clean_value(val):
    if pd.isna(val):
        return ""
    s = str(val).strip()
    # Supprime les guillemets r√©siduels encadrants (cas rares d'exports non-standard)
    if len(s) >= 2 and s.startswith('"') and s.endswith('"'):
        s = s[1:-1].replace('""', '"')
    return s


def convert(filepath):
    df = load_file(filepath)
    print(f"\n‚úì   {len(df)} lignes lues")
    print(f"‚úì   Colonnes : {list(df.columns)}\n")

    quote_cols = [c for c in df.columns if any(kw in c.lower() for kw in ["quote", "phrase"])]
    if not quote_cols:
        print("‚ö†Ô∏è   Colonne 'Insert quote' non trouv√©e ‚Äî toutes les lignes seront export√©es.")

    records, skipped = [], 0
    for _, row in df.iterrows():
        record = {col: clean_value(row[col]) for col in df.columns}
        if quote_cols and not record.get(quote_cols[0]):
            skipped += 1
            continue
        records.append(record)

    if skipped:
        print(f"‚ÑπÔ∏è   {skipped} ligne(s) ignor√©e(s) (phrase vide)")

    # Aper√ßu
    print(f"üëÅ   Aper√ßu des 3 premi√®res phrases :")
    qk = quote_cols[0] if quote_cols else None
    nk = next((c for c in df.columns if "name" in c.lower()), None)
    for r in records[:3]:
        q = (r.get(qk, "?") or "?")[:70]
        a = r.get(nk, "?") if nk else "?"
        print(f"     [{a}]  {q}")

    output_path = Path(filepath).parent / "data.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(records, f, ensure_ascii=False, indent=2)

    print(f"\n‚úÖ  {len(records)} phrases ‚Üí {output_path}")
    print("\n   Uploadez ce data.json sur votre d√©p√¥t GitHub Pages pour mettre √† jour l'app.\n")


if __name__ == "__main__":
    filepath = sys.argv[1] if len(sys.argv) > 1 else find_file()

    if not filepath:
        print("‚ùå  Aucun fichier CSV/TSV/Excel trouv√© dans le dossier.")
        print("    Usage : python convert_to_json.py mon_fichier.tsv")
        sys.exit(1)

    if not os.path.exists(filepath):
        print(f"‚ùå  Fichier introuvable : {filepath}")
        sys.exit(1)

    convert(filepath)
